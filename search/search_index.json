{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Memory Collector","text":"<p>A Kubernetes-native collector for monitoring memory subsystem interference between pods. This project is under active development and we welcome contributors to help build this critical observability component.</p>"},{"location":"#overview","title":"Overview","text":"<p>Memory Collector helps Kubernetes operators identify and quantify performance degradation caused by memory subsystem interference (\"noisy neighbors\") by collecting metrics about:</p> <ul> <li>Memory bandwidth utilization</li> <li>Last Level Cache (LLC) usage</li> <li>CPU performance counters related to memory access</li> </ul> <p>This data helps operators: - Identify when pods are experiencing memory subsystem interference - Quantify the performance impact of noisy neighbors - Build confidence before deploying memory interference mitigation solutions</p>"},{"location":"#why-this-matters","title":"Why This Matters","text":"<p>Memory subsystem interference can cause: - 25%+ increase in cycles per instruction (CPI) - 4x-13x increase in tail latency - Reduced application performance even with CPU and memory limits</p> <p>Common sources of interference include: - Garbage collection - Big data analytics - Security scanning - Video streaming/transcoding - Container image decompression</p>"},{"location":"#development-status-contributing","title":"Development Status &amp; Contributing","text":"<p>The project is in active development across several areas:</p>"},{"location":"#core-metrics-collection","title":"Core Metrics Collection","text":"<ul> <li>Implementing collection for Intel RDT and AMD QoS</li> <li>Collecting hardware performance counters: cycles, instructions, cache misses</li> <li>Defining Prometheus metrics</li> </ul>"},{"location":"#kubernetes-integration","title":"Kubernetes Integration","text":"<ul> <li>Helm chart, DaemonSet implementation</li> <li>Prometheus integration</li> </ul>"},{"location":"#testing-documentation","title":"Testing &amp; Documentation","text":"<ul> <li>Architecture documentation</li> <li>Benchmark suite with example workloads</li> <li>Integration testing framework</li> </ul>"},{"location":"#get-involved","title":"Get Involved","text":"<p>We welcome contributions! Here's how you can help:</p> <ul> <li>Code: Check our Good First Issues and Development Guide</li> <li>Use Cases: Share interference scenarios, test in your environment</li> <li>Discussion: Open GitHub Issues or email yonch@yonch.com</li> <li>Schedule a chat: https://yonch.com/collector</li> </ul>"},{"location":"#project-background","title":"Project Background","text":"<p>This project builds on research and implementation from: - Google's CPI\u00b2 system - Meta's Resource Control implementation - Alibaba Cloud's Alita system - MIT's Caladan project</p>"},{"location":"#license","title":"License","text":""},{"location":"#code","title":"Code","text":"<p>Licensed under the Apache License, Version 2.0</p>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is licensed under a Creative Commons Attribution 4.0 International License.</p>"},{"location":"devlog/","title":"Devlog","text":"<p>Documentation of development steps, environment, and dependencies  </p> <ul> <li>Contributors: atimeofday</li> <li>Goals: Create skeleton collector with Prometheus endpoint</li> <li>Issues: https://github.com/perfpod/memory-collector/issues/19</li> </ul> <p>Initial environment and tools:</p> <pre><code># Shell: Bash\ndistrobox create --image fedora:40 --name memory-collector \ndistrobox enter memory-collector\nsudo dnf install git go\n\n# cd to preferred project directory\n# Clone (fork of) project\ngit clone https://github.com/perfpod/memory-collector\ncd memory-collector\n</code></pre> <p>Issue 19 objective 1: Create a <code>main.go</code> file in <code>cmd/collector</code></p> <pre><code>mkdir -p cmd/collector\ncd cmd/collector\ntouch main.go\n</code></pre> <ul> <li>Prometheus client_golang reference guide: https://prometheus.io/docs/guides/go-application/</li> <li>Go package installation reference: https://go.dev/doc/go-get-install-deprecation</li> <li>Go Module reference: https://go.dev/ref/mod#go-mod-init</li> <li><code>go get</code> and <code>go install</code> require a Go Module and/or @version tag as of Go 1.17 in August 2021</li> <li>Prometheus go_client installation instructions appear to be outdated and missing a piece</li> <li>Submitted issue to Prometheus documentation repository: https://github.com/prometheus/docs/issues/2556#issue-2736636166</li> <li>Proceeded with Prometheus client_golang guide </li> </ul> <pre><code>cd cmd/collector\ngo mod init memory-collector\ngo get github.com/prometheus/client_golang/prometheus\ngo get github.com/prometheus/client_golang/prometheus/promauto\ngo get github.com/prometheus/client_golang/prometheus/promhttp\n</code></pre> <p>Issue 19 objective 2: Expose an endpoint on a known fixed port </p> <pre><code># Wrote and tested example Go exposition application from Prometheus guide\ngo run main.go &amp;\ncurl http://localhost:2112/metrics\n</code></pre> <p>Issue 19 objective 3: Expose the <code>up</code> metric with value 1</p> <pre><code>// Created, registered, and set an 'up' metric in func main()\n\nupMetric := prometheus.NewGauge(prometheus.GaugeOpts{\n    Namespace:  \"perfpod\",\n    Subsystem:  \"memory_collector\",\n    Name:       \"up_metric\",\n    Help:       \"Test metric to confirm skeleton application functionality.\",\n})\nprometheus.MustRegister(upMetric)\n\nupMetric.Set(1)\n</code></pre> <p>Issue 19 objective 4: Manually verify: query the endpoint using <code>curl</code> or <code>wget</code></p> <pre><code>curl -s http://localhost:2112/metrics | grep up_metric\n</code></pre> <p>Output:</p> <pre><code># HELP perfpod_memory_collector_up_metric Test metric to confirm skeleton application functionality.\n# TYPE perfpod_memory_collector_up_metric gauge\nperfpod_memory_collector_up_metric 1\n</code></pre> <p>Issue 19 objective 5: Move the code into a function (not <code>main()</code>)</p> <pre><code>// Moved Up metric into \"func recordMetrics()\" and added function call in main()\n\nfunc main() {\n    recordMetrics()\n\n    http.Handle(\"/metrics\", promhttp.Handler())\n    http.ListenAndServe(\":2112\", nil)\n}\n\n// Repeated manual verification endpoint query\n</code></pre> <p>Issue 19 objective 6: Add an integration test that verifies the metrics are up, using client_golang's testutil - TO DO - May require assistance</p> <ul> <li>Issue 19 split into 5/5 done and new Issue 20</li> <li>Issue 19 5/5 PR opened and merged</li> </ul> <ul> <li>Contributors: atimeofday</li> <li>Goals: Add integration test to Prometheus endpoint</li> <li>Issues: https://github.com/perfpod/memory-collector/issues/20</li> </ul> <p>Research &amp; references:</p> <pre><code>https://go.dev/doc/tutorial/add-a-test\nhttps://albertmoreno.dev/posts/testing-prometheus-metrics-in-integration-tests-in-golang/\nhttps://github.com/prometheus/client_golang/blob/main/prometheus/testutil/testutil.go\nhttps://github.com/prometheus/client_golang/blob/main/prometheus/testutil/testutil_test.go\n</code></pre> <pre><code>go get github.com/prometheus/client_golang/prometheus/testutil \ngo get github.com/stretchr/testify/require\n</code></pre> <p>Go test format:</p> <pre><code>[filename]_test.go\n\nimport(\n    [...]\n)\n\nfunc [TestFunction](t *testing.T) {\n    // Set test values\n    // Perform test\n}\n\n// Perform more tests\n</code></pre> <ol> <li>Created skeleton test based on examples </li> </ol> <pre><code>func TestMetricsUp(t *testing.T) {\n    require.Eventuallyf(t, func() bool {\n\n        // Test values\n        // ??? expected format\n\n        if err := testutil.ScrapeAndCompare(serverURL+\"/metrics\", strings.NewReader(expected), metricName); err == nil {\n            return true\n        } else {\n            t.Log(err.Error())\n            return false\n        }\n    }, time.Second, 100*time.Millisecond, \"Could not find metric %s with value %d\", metricName, expectedMetricValue)\n}\n</code></pre> <ol> <li>Checked the implementation of the testutil ScrapeAndCompare function, and notably, the implementation of its own integration test.</li> <li>Located and implemented the exact input template required by the function, then implemented generalized code for the template.</li> <li>Researched goroutines to allow automatically initializing the (currently local) remote server to be tested.</li> </ol> <pre><code>go main()\ntime.Sleep(1 * time.Second)\n</code></pre> <ol> <li>Refined logical flow from example code for improved readability.</li> </ol> <ul> <li>Issue 20 done</li> </ul> <ul> <li>Contributors: </li> <li>Goals: </li> <li>Issues: </li> </ul>"},{"location":"architecture/decisions/2024-12-21-container-notifications/","title":"2024-12-21: Notifications for container lifecycle events","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#status","title":"Status","text":"<p>Draft, WIP</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#context","title":"Context","text":"<p>We'd like the collector to show how memory resource contention influences container performance.</p> <p>To do that, we'd need to monitor: 1. Resource contention - can do this with <code>resctrl</code>, or by monitoring LLC Misses using perf counters 2. Container performance - current plan is to do this by monitoring CPI (cycles per instruction)</p> <p>For CPI monitoring, we'd need to have an inventory of containers on the system, and correctly instrument them as they arrive/go. In this issue, we add a component to monitor the arrival and departure of containers in the system.</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#options-considered","title":"Options considered","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#kubelet-api","title":"Kubelet API","text":"<p>If we're focusing on Kubernetes, kubelet provides an HTTP API accessible locally. This appears to be an undocumented, unstable API, that is nevertheless available in kubelet.</p> <p>Stack overflow discussion points to a project kubeletctl. The referenced blog post shows several <code>curl</code> commands to interact with the API. According to the blog post, this is available because the default kubelet configuration allows for anonymous (unauthenticated) requests, so this relies on users not fortifying their systems to this vulnerability. The specific implementation in kubeletctl appears a thin implementation of HTTP calls, so it might be best to reimplement this in our on library rather than take a dependency.</p> <p>Pros: - Should provide metadata on Pods, not only containers - Does not rely on a specific container runtime (docker, containerd, etc.)</p> <p>Cons: - Undocumented, unstable API - Requires access to kubelet, which may not be available in all environments - Appears to require polling (no <code>watch</code>). If so, will react slowly and incur more overhead.</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#filesystem-watch-on-the-cgroup-directory-eg-inotify","title":"Filesystem watch on the cgroup directory (e.g., <code>inotify</code>)","text":"<p>This is the method used by Koordinator.sh in its PLEG component. It watches the cgroup root path for each of the Kubernetes QoS classes, for new pod directories. A new pod directory adds that pod subdirectory to a container watcher, which then issues container events.</p> <p>Pros: - Does not require access to kubelet - Does not depend on a container runtime - ABI is stable and well-documented - Supports inotify, which is efficient and low-overhead</p> <p>Cons: - Does not provide metadata beyond the pod and container IDs</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#cri-container-runtime-interface-events","title":"CRI (Container Runtime Interface) events","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#kubernetes-api-ie-watching-the-control-plane","title":"Kubernetes API (i.e., watching the control plane)","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#decision","title":"Decision","text":""}]}